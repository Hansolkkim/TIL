* CS10 강의 내용 정리

## CS07 | 프로세스 스케줄링

### 운영체제 역사

> 역사적으로 어떤 순서대로 만들어졌는지, 예전 시스템들은 어떻게 생겼고 요즘 시스템은 어떻게 생겼고 그 사이에 어떤 변화가 있었는지를 시간의 흐름에 따라서 보는 것이 무언가를 이해하는데 많은 도움이 됩니다.
>
> 옛날 시스템이 왜 그랬었고, 거기에 뭐가 필요해서 다음엔 어떤 시스템이 만들어졌고, 이런 차이점들을 학습하다보면 현대적인 시스템들이 왜 그런 형태를 가지고 있는지를 조금 더 알기 쉽게 접근할 수 있습니다.
>
> 그리고 시스템에서 사용되는 용어들도 한 번 그 이름이 붙어지면 관용적으로 계속 그 용어를 쓰는 경우가 많으니, 용어에 대해 궁금하다면 그 용어가 붙은 이유를 알고 있으면 이해하기에 편할 것입니다.

1. 초기 단일 시스템

	<img src="https://user-images.githubusercontent.com/92504186/150926439-1e6dc4d0-58d3-4ee6-a485-5ef58fb42980.jpg" alt="SS 2022-01-25 PM 03 54 47" style="zoom:50%;" />

	* 요즘은 컴퓨터라하면 특정 목적이 있는게 아니라 어떤 프로그램을 실행하느냐에 따라 다른 목적이 되는 포괄적인 목적에서의 컴퓨터, General Purpose Computer를 의미한다.

		하지만 초기의 컴퓨터라 불렸던 시스템들은 단일 목적이었다. (전원을 입력하면 코드를 입력하는 프롬프트만 뜸..)

		따라서 컴퓨터에 어떤 입력을 주기 위해서는 입력할 내용을 모두 컴파일러처럼 작업해서 정리해서 프로세서의 특정한 위치에다가 입력을 주고 버튼을 누르면 출력되는 식이었기 때문에, 그런 작업을 해주는 `Operator`가 필수적으로 필요했다.(Operator: 컴퓨터를 운영할줄 아는 사람)

		

2. 일괄 처리 시스템

	<img src="https://user-images.githubusercontent.com/92504186/150927595-8f46c414-d668-4c2e-bc1e-d80c843cb7d9.jpg" alt="SS 2022-01-25 PM 04 04 27" style="zoom:50%;" />

	* 에러가 발생하면 다시 코드를 카드로 작성해 Operater에게 가져다 주고 하는 작업을 개선하고자, `Operating System(OS)`를 만들게 됐다.

		메모리에다가 프로그램을 다 올리고, 올린 내용들을 차례차례 실행하도록 하는 컴퓨터를 생각했고, 그 올리는걸 관리해주는 프로그램이 OS의 시작이었다. (거주관리(resident management): 한꺼번에 내용을 다 올리고, 그 내용을 차례차례 실행하면서, 올린걸 관리해주는 방법)

	* 이제 OS가 관리해주기 때문에 프로그램을 빨리빨리 교체가 가능해졌다. 하지만 프로그램을 올리고 실행까지해서 일괄적으로 처리를 해야하기 때문에, `배치 프로세싱`을 사용하게 됐다.(요즘엔 배치라는 용어의 의미가 프로그램이 끝날 때까지 입력과 출력을 다 멈춰놓고, 프로그램이 끝나면 입력과 출력을 한꺼번에 처리하는 걸 의미함)



3. 다중 프로그래밍 시스템 (CPU 스케줄링)

	<img src="https://user-images.githubusercontent.com/92504186/150930246-4d334a1b-8670-4e0b-a934-4f8c64a6d518.jpeg" alt="IMG_90B7E1F1278D-1" style="zoom:50%;" />

	* 프로그램이 돌아가는 동안 입력, 출력을 한꺼번에 다 기록해놨다가, 프로그램 동작이 끝나면 일괄적으로 처리하는 방법이 생겨나니까, 이제 점점 여러 프로그래밍이 돌아가는게 필요한 시대가 됐다.

	* 프로그램을 컴퓨터에 올리는 방법은 TypeWriter를 사용했다.

	* 이제 프로그램이 바로 출력을 하는게 아니라 I/O로 사용되는 Tape에 출력을 저장하게 됐는데, I/O 저장장치는 컴퓨터에 비해 매우 느리게 동작했기 때문에, 컴퓨터의 프로그램A가 저장장치에 값을 쓰거나 읽어와야하는 순간에는 해당 컴퓨터의 프로그램A가 정지되고 읽어오거나 쓰는 작업이 끝나면 이제 프로그램A의 차례가 끝나고 B로 넘어가게 됐다.

		이렇게 되니, 프로그램이 멈춰있는 동안 컴퓨터의 CPU가 놀게 되는 경우가 생기기 때문에 `CPU 스케줄링`이 필요하게 됐다. I/O로 가야할 경우가 생기면 실행중인 프로그램 말고 다른 프로그램을 돌리고 하는 방법을 사용하게 되었고, 이 방법을 멀티 프로그래밍이라고 불렀다.



4. 시분할 시스템

	<img src="https://user-images.githubusercontent.com/92504186/150932420-22384754-5ab7-41eb-a56e-ffd5332881c9.jpg" alt="SS 2022-01-25 PM 04 38 25" style="zoom:50%;" />

	* 다중 프로그래밍 시스템에서는, 만약 프로그램A를 쓰려는 사람이 있으면, A가 돌아가다 멈추고, B,C가 돌아가고 B,C도 끝나야 A가 끝날 수 있는 기회를 얻게 되므로, 아직 여러 명이 동시에 쓰기에는 불편한 시스템이었다. 이를 개선하고자 시분할(Time Sharing) 시스템이 생겼다.

		시분할 시스템은 정해놓은 시간동안 규칙적으로 번갈아가면서 프로그램들이 돌아가게 된다. -> UNIX의 시초



5. 인터럽트 기반 시스템

	<img src="https://user-images.githubusercontent.com/92504186/150933821-4ba8529d-ce5c-45dc-beab-ba2da9a70f14.jpg" alt="SS 2022-01-25 PM 04 43 42" style="zoom:50%;" />

	* 하드웨어에 있는 키보드/마우스가 움직일 때마다 CPU한테 인터럽트를 넣어준다. 하드웨어를 통한 입력을 메인 메모리 어딘가에 저장하면서 인터럽트를 발생시켜준다. 
	* 부트로더는 바이오스라 해서, 어떤 운영체제가 깔려있는지를 확인해서 로딩해주는 작은 프로그램이다.



### Virtual Memory와 Data Bus

<img src="https://user-images.githubusercontent.com/92504186/150934758-a73278b5-a80c-4083-bd2e-75f994e0f8a7.jpg" alt="SS 2022-01-25 PM 04 54 08" style="zoom:50%;" />

> 왜 Bus라고 부를까? -> 정해진 (여러)경로를 일정 시간마다 왔다갔다 하기 때문
>
> 시스템 메모리 뿐 아니라, 비디오 카드도 연결하고, 하드 디스크도 연결함



### 컴퓨터 구조

![IMG_D2716C79F9BA-1](https://user-images.githubusercontent.com/92504186/150935219-80f75b6b-0367-49c3-ba48-095e4d152d21.jpeg)

* Queue? -> 대기열, 줄을 의미하는 단어

	cf) Buffer? -> 기차 사이 완충장치를 의미하는 단어

* CPU와 메인 메모리 간의 속도차가 크기 때문에, 누군가가 계속 스케줄링 해줘야 할 필요성이 있다. 

* Job Scheduler는 CPU 입장에서는 되게 느린 스케줄러이기 때문에 Long-term Scheduler라고 하고, CPU Scheduler는 굉장히 빠르게 프로세스들을 바꿔줘야 하기 때문에 Short-term Scheduler라고 한다.

* Job을 메모리에 로딩하면 Process가 만들어짐



### 프로세스

![150080335-e707150e-9ad4-4dc8-b259-79eef50b2e40](https://user-images.githubusercontent.com/92504186/150936318-403a9770-348d-49be-a3b8-ea9874ae2cc0.png)



* CS07 학습정리

# CS07 | 프로세스 스케줄링

## 📌셀프 체크리스트

*  프로세스 작업 정보 데이터 구조 구현
*  프로세스 종류 4개 구현
*  1초마다 프로세스 스케줄링 구현
*  프로세스 상태 변경
*  프로세스 상태 누적 표시
*  스레드 개수 표시
*  2초마다 스레드 스케줄링 구현

## 📌스스로 확인할 사항

### 1. 멀티 스레드 스케줄링 방식에 대해 학습하고 정리한다.

* 멀티 스레드란 프로그램을 실행할 때 동시에 다수의 처리를 병행하기 위해 여러 개의 스레드를 생성해 운영하는 방법을 말합니다.

	멀티 스레드는 Concurrency와 Parrallelism 방식으로 실행됩니다.

	* Concurrency

		프로세서가 여러개의 스레드를 하나씩 몇 초 간격으로 실행 → 이게 매우 빨리 진 행되므로, 사용자는 여러 프로세서스가 동시에 진행된다고 인식하게 됨

		이렇게 여러 개의 프로세스를 하나씩 선택하는 것을 `Context Switching` 이라고 한다.

	* Parrallelism

		프로세서 하나에 코어가 여러개 달려서, 각각의 코어들이 동시에 스레드를 실행함

* 멀티 스레드 스케줄링 방식에는 아래의 방식들이 있습니다.

	* Priority : 우선순위가 높은 스레드가 더 자주 실행되도록 스케줄링하는 알고리즘을 의미합니다.
	* Round-Robin : 순환 할당방식으로, 시간 할당량(Time Slice)를 정해 하나의 스레드를 정해진 시간만큼 실행하고 다시 다른 스레드를 실행하는 알고리즘을 의미합니다.

### 2. 각자 운영체제 스레드 동작 방식과 본인이 작성한 스레드 스케줄링 방식을 비교한다.

* 잘 모르겠습니다..

### 3. 스레드를 무제한으로 만들 수 없다면, 프로세스가 많아질 때 성능 향상을 할 수 있는 방법이 무엇일까?

* 하나의 프로그램을 병렬 처리를 통해 속도를 향상시킬 수 있습니다.
* 여러 CPU를 이용해, 각 CPU마다 병렬처리로 스케줄링하여 처리속도를 올릴 수 있습니다.

### 4. setTimeout 내부 동작 방식에 대해 학습하고 정리한다.

* setTimeout?

	일정 시간이 지난 후에 원하는 함수를 예약 호출할 수 있게 하는 호출 스케줄링을 구현하는 방법 중 하나로, 일정 시간이 지난 후에 함수를 실행합니다.

	```
	 let timerID = setTimeout(func|code, [delay], [arg1], [arg2], ...)
	```

	> 매개변수
	>
	> * `func|code` : 실행하고자 하는 코드로, 함수 또는 문자열 형태.
	> * `delay` : 실행 전 대기 시간으로, 단위는 밀리초.(default : 0)
	> * `arg1`,`arg2`,... : 함수에 전달할 인수.

	`setTimeout`은 비동기 함수로서, 함수 스택의 다른 함수 호출을 막지 않습니다.

	```
	 setTimeout(() => {console.log("첫 번째 메시지")}, 5000);
	 setTimeout(() => {console.log("두 번째 메시지")}, 3000);
	 setTimeout(() => {console.log("세 번째 메시지")}, 1000);
	 
	 // Prints :
	 // 세 번째 메시지
	 // 두 번째 메시지
	 // 첫 번째 메시지
	```

	즉, 첫 번째 `setTimeout()`의 호출이 두 번째 호출 전에 5초의 정지 구간을 만들지 않습니다. 그 대신, 위 코드는 첫 함수 실행을 5초간 대기하는 동시에 두 번째 함수 실행을 3초간 대기하고, 다시 동시에 세 번째 함수의 실행도 1초간 대기합니다.

* 내부 동작 방식

	언어들 대부분 공통적으로 함수를 실행시키면 함수가 call stack에 쌓이며 LIFO방식으로, 나중에 들어온 함수부터 처리합니다.

	[![SS 2022-01-26 AM 12 31 41](https://user-images.githubusercontent.com/92504186/151007195-c617bce3-ecfd-454d-84bd-8f406951ab87.jpg)](https://user-images.githubusercontent.com/92504186/151007195-c617bce3-ecfd-454d-84bd-8f406951ab87.jpg)

	JS는 싱글 스레드로 동작하므로, 1개의 call stack에서 함수를 처리합니다. 이 때, jquery로 getSync함수를 호출하면, 해당 함수가 리턴될 때까지 로딩상태에 빠져, 다음 함수들은 동작하지 못 하게 됩니다.

	[![SS 2022-01-26 AM 12 34 19](https://user-images.githubusercontent.com/92504186/151007685-9d32b0a4-09bf-415a-85d3-af20ad94b9d5.jpg)](https://user-images.githubusercontent.com/92504186/151007685-9d32b0a4-09bf-415a-85d3-af20ad94b9d5.jpg)

	이 문제를 해결할 수 있는 방법은 바로 비동기 콜백함수인 `setTimeout`함수를 사용하는 것입니다. 해당 함수를 사용하면, 입력한 `delay`만큼의 시간이 지난 후 콜백 함수가 동작하게 됩니다.

	[![SS 2022-01-26 AM 12 35 42](https://user-images.githubusercontent.com/92504186/151007945-b67d7fab-e23d-47ea-a2fc-4f80a67b1447.jpg)](https://user-images.githubusercontent.com/92504186/151007945-b67d7fab-e23d-47ea-a2fc-4f80a67b1447.jpg)

	즉, `setTimeout`함수가 먼저 stack에 등록되었다가 실행되면서 사라지고, 다음에 주어진 `console.log('JSConfEU')`가 실행되고 5초가 지난 후 콜백함수의 내용인 `console.log('there')`가 실행됩니다.

	동작 원리는, setTimeout은 stack에 쌓이게 되고, 비 동기적으로 동작하기 때문에 setTimeout의 Timer를 브라우저가 제공하는 webapi에 등록됩니다. 그리고 call stack에 setTimeout함수는 사라지고, 그 아래에 있는 `console.log('JSConfEU')`함수가 stack에 쌓여 실행되고 사라집니다. 그리고 main 함수도 코드가 끝까지 실행되었으므로 stack에서 사라지고, webapi에 등록된 타이머는 계속 동작하다가 5초가 됐을 때 동작을 중지하고 콜백함수를 task queue로 전달합니다. task queue에서 대기중이던 콜백함수는 stack에 아무런 함수가 쌓이지 않았을 때 queue에서 빠져나와 call stack으로 넘어가 실행되게 됩니다. 이와 같은 동작 원리로 웹의 비동기 처리가 진행됩니다.

* Swift에서의 비동기 처리방식

	Swift, iOS에서는 GCD를 이용해 비동기를 처리합니다.

	GCD는 DispatchQueue라는 큐를 관리합니다. 그리고 이 큐에서는 Serial 큐와 Concurrent 큐가 존재합니다. Serial 큐는 작업을 순서대로 하나씩 처리합니다.(하나의 작업이 끝날 때까지 다음 작업으로 넘어가지 않습니다.) Concurrent 큐는 작업을 여러 스레드에 분산 배치한 후 동시에 처리합니다. 대신 작업 완료 순서는 보장되지 않습니다.

	![SS 2022-01-26 AM 10 29 39](https://user-images.githubusercontent.com/92504186/151087917-9bba666c-b2b3-43b1-a735-55b1788844f3.jpg)

	![SS 2022-01-26 AM 10 30 13](https://user-images.githubusercontent.com/92504186/151087969-91195b77-cfba-4976-bd4b-2d33d07e8b85.jpg)

	Serial 큐는 하나의 스레드에 차곡차곡 순서대로 쌓고, Concurrent 큐는 여러 스레드에 분산 배치합니다. Serial 큐는 DispatchQueue.main이고, Concurrent 큐는 DispatchQueue.global()이라고 보면 됩니다.

	`sync`는 동기 처리 메소드, `async`는 비동기 처리 메소드입니다. 동기 처리 메소드 sync는 주어진 작업이 완료될 때까지 다음 작업으로 넘어가지 않고, 비동기 처리 메소드 async는 작업 전달 후 바로 다음 작업으로 넘어갑니다.

	Swift iOS 프로그래밍에서 스레드 관리는 위에서 말씀드린 것들을 조합하여 4가지 조합으로 할 수 있습니다. Serial큐-sync, Serial큐-async, Concurrent큐-sync, Concurrent큐-async의 4가지 조합입니다.

	* **Serial 큐 - sync**

		```swift
		DispatchQueue.main.sync{}
		```

		위의 코드를 이용하는 방법입니다. 하지만 현재 iOS 프로그래밍에서는 데드락이 발생하여 사용이 불가능해졌습니다. sync 메소드는 주어진 작업이 끝날 때까지 이전 작업 스레드를 블락하고 기다립니다. 만약 메인 스레드에서 sync 메소드를 부르면 메인 스레드가 블락돼버리는 문제가 발생합니다. 아직 처리해야할 작업이 메인 스레드에 있기 때문에, 작업은 실행되지도 않게 됩니다. 이런 데드락을 피하고자 현재 iOS 프로그래밍에서는 해당 코드의 사용이 금지되어 있습니다.

	* **Serial 큐 - async**

		```swift
		DispatchQueue.main.async{}
		```

		위의 코드를 이용하는 방법입니다. 메인 스레드로 작업을 순서대로 전달하되, 떠넘기기만 할 뿐 완료를 기다리지 않습니다. Serial 큐를 사용하므로 작업을 하나의 스레드에 순서대로 전달하고, async 메소드를 사용하므로 완료를 기다리지 않고 곧 바로 다른 작업을 진행할 수 있습니다.

		해당 방법은 UI 관련 작업을 할 때 주로 사용됩니다.

	* **Concurrent 큐 - sync**

		```swift
		DispatchQueue.global().sync{}
		```

		위의 코드를 이용하는 방법입니다. 다른 여러 스레드로 작업을 분산 배치하고, 배치한 작업들이 모두 완료될 때까지 이전 스레드를 블락하고 기다립니다. Concurrent 큐를 이용하므로 작업을 여러 스레드로 분산 배치하고, sync 메소드를 이용하므로 완료를 기다리게 되는 것입니다.

	* **Concurrent 큐 -  async**

		```swift
		DispatchQueue.global().async{}
		```

		위의 코드를 이용하는 방법입니다. 작업을 여러 스레드로 분산 배치하되, 완료를 기다리지 않습니다. Concurrent 큐를 이용하므로 작업을 여러 스레드로 분산 배치하고, async 메소드를 사용하므로 완료를 기다리지 않습니다.

		해당 방법은 주로 API 통신 등을 할 때 주로 사용됩니다.

	```swift
	print(1)
	DispatchQueue.global().sync {
	    print(2)
	}
	DispatchQueue.global().sync {
	    print(3)
	    print(4)
	}
	DispatchQueue.main.async {
	    print(5)
	    print(6)
	    print(7)
	}
	print(8)
	DispatchQueue.global().async {
	    print(9)
	}
	DispatchQueue.global().sync {
	    print(10)
	}
	```

	해당 코드를 실행하면 우선 가장 윗 줄의 `print(1)` 함수가 실행되어 1이 출력될 것입니다.

	그 다음 `DispatchQueue.global().sync{print(2)}` 함수가 실행됩니다. Concurrent큐-sync 조합이므로, 작업을 여러 스레드로 분산하고 작업의 완료를 기다리게 됩니다.

	그 다음 `DispatchQueue.global().sync{print(3);print(4)}`함수가 실행됩니다. sync 메소드를 사용하므로 작업이 완료될 때까지 다른 작업이 실행되지 않으므로 3,4가 출력됩니다.(이 경우, Concurrent큐를 사용했기 때문에 완료 순서가 보장되지 않지만, print()라는 간단한 함수 작업이 진행되므로 순서대로 3,4가 출력됩니다.)

	그 다음에는 `DispatchQueue.main.async{print(5);print(6);print(7)}`함수가 실행됩니다. Serial 큐를 사용하므로 작업을 순서대로 메인 스레드에 전달합니다. 하지만 async 메소드를 사용하기 때문에 전달만 할 뿐, 작업의 완료를 기다리지 않습니다. 즉, 프로그램이 이 코드를 지나쳐 갈 때 5,6,7은 출력되지 않습니다.

	그리고 다음 라인의 `print(8)`함수가 실행되어 8이 출력됩니다.

	다음 순서로 `DispatchQueue.global().async{print(9)}`함수가 실행됩니다. async 메소드를 사용했으므로 완료를 기다리지 않으므로, 프로그램이 이 코드를 지나쳐 갈 때 9는 출력되지 않습니다.

	다음으로 `DispatchQueue.global().sync{print(10)}`함수가 실행됩니다. sync 메소드를 사용했기 때문에 완료를 기다려 10이 출력되게 됩니다.

	지금까지 1,2,3,4,8,10이 출력되었고 5,6,7,9는 어떤 순서로 출력될지는 알 수 없습니다. async 메소드로 결과를 기다리지 않고 넘어간 작업이 어떤 순서로 완료되는지는 GCD에 달렸습니다. 하지만 5,6,7의 순서는 바뀌지 않습니다. 5,6,7은 Serial 큐를 이용한 `DispatchQueue.main.sync{}`메소드를 사용했으므로, 작업이 순서대로 진행되기 때문입니다.

	<img src="https://user-images.githubusercontent.com/92504186/151104081-d56babbf-637b-48c1-8b31-4ea9f5c42962.jpg" alt="SS 2022-01-26 PM 01 29 08" style="zoom:50%;" />

## 📌다 같이 확인할 사항

### 1. (setTimeout을 제외하고) 플랫폼에서 정확도 높은 타이머를 구현하기 위한 여러 방식에 대해 학습한다.

* Timer 클래스를 이용하는 방법

	```javascript
	 import java.util.Timer;
	 import java.util.TimerTask;
	 public class JavaTimerTest {
	     public static void main(String[] args) {
	         TimerTask task = new TimerTask() {
	             @Override
	             public void run() {
	                 int result = 0;
	                 // 특정 로직
	                 for(int i=0;i<10000;i++) {
	                     for(int j=0;j<10000;j++) {
	                         result = i+j;
	                     }
	                 }
	                 //이부분에 send()같은 것이 들어갈 것
	                 System.out.println(System.currentTimeMillis());
	             }
	         };
	         Timer timer = new Timer();
	         timer.scheduleAtFixedRate(task, 0, 1000);
	     }
	 }
	```

	TimerTask를 만들고 특정로직은 for loop로 1억번 반복하는 코드로 설정했습니다. 그리고 timer객체의 `.scheduleAtFixedRate(task, delay, period)`메소드를 호출했습니다. 해당 메소드는 task를 delay만큼 지연시킨 후에 period마다 실행하는 메소드입니다.

* ScheduledExecutorService 클래스를 이용하는 방법

	```javascript
	 import java.util.concurrent.Executors;
	 import java.util.concurrent.ScheduledExecutorService;
	 import java.util.concurrent.TimeUnit;
	  
	 public class JavaTimerTest {
	     public static void main(String[] args) {
	         Runnable runnable = new Runnable() {
	             int result=0;
	             @Override
	             public void run() {
	                 for(int i=0;i<10000;i++) {
	                     for(int j=0;j<10000;j++) {
	                         result = i+j;
	                     }
	                 }
	                 //이부분에 send()같은 것이 들어갈 것
	                 System.out.println(System.currentTimeMillis());
	             }
	         };
	         ScheduledExecutorService service = Executors.newSingleThreadScheduledExecutor();
	         service.scheduleAtFixedRate(runnable, 0, 100, TimeUnit.MILLISECONDS);
	     }
	 }
	```

	해당 서비스를 만들어서 Timer와 유사하기 `scheduledAtFixecRate(실행가능객체, 지연시간, 주기, 단위)`를 사용합니다.

### 2. 멀티 스레드가 공용 리소스에 접근할 때 임계구역을 다루는 방식(Semaphore, Mutex 등)에 대해 학습하고, 어떤 경우에 사용해야 하는지 토론한다.

* 임계구역(Critical Section)

	다중 프로그래밍 운영체제에서 여러 프로세스가 데이터를 공유하면서 수행될 때 **각 프로세스에서 공유 데이터를 접근(Access)하는 프로그램 코드 부분**을 가리키는 말입니다.

	공유 데이터를 여러 프로세스(스레드)가 동시에 Access하면 시간적인 차이 등으로 잘못된 결과를 만들어 낼 수 있기 때문에, 한 프로세스(스레드)가 공유 데이터를 Access하고 있을 때는 다른 프로세스(스레드)들은 절대 그 데이터를 Access하지 못하도록 해야 합니다.

* Semaphore(깃발)

	공유 리소스에 여러 프로세스(스레드)가 동시에 접근하면서 문제가 발생하여, 공유된 리소스 속 하나의 데이터는 한 번에 하나의 프로세스(스레드)만 접근할 수 있도록 제한해 두어야 하는데 이를 위해 고안된 것이 Semaphore입니다.

	Semaphore는 리소스의 상태를 나타내는 간단한 카운터로 생각할 수 있습니다.(Semaphore는 shared data의 개수를 의미하므로)일반적으로 비교적 긴 시간을 확보하는 리소스에 대해 이용하게 되며, 유닉스 시스템의 프로그래밍에서 Semaphore는 운영체제의 리소스를 경쟁적으로 사용하는 다중 프로세스에서 행동을 조정하거나 동기화 시키는 기술입니다.

	Semaphore는 공유된 리소스의 데이터 혹은 임계영역 등에 여러 프로세스 /스레드가 접근하는 것을 막아줍니다. 즉, 동기화 대상이 하나 이상이 되게 제한합니다.

* Mutex

	Mutual Exclusion으로, 상호 배제라고도 합니다. 임계구역을 가진 스레드들의 Running Time이 서로 겹치지 않게 각각 단독으로 실행되게 하는 기술입니다. 다중 프로세스(스레드)들의 공유 리소스에 대한 접근을 조율하기 위해 locking과 unlocking을 사용합니다.

	공유된 리소스의 데이터 혹은 임계영역 등에 하나의 프로세스 /스레드가 접근하는 것을 막아줍니다. 즉, 동기화 대상이 하나가 되도록 제한합니다.

* 차이점

	Mutex는 동기화 대상이 오직 하나 뿐일 때, Semaphore는 동기화 대상이 하나 이상일 때 사용합니다.

	Mutex는 Locking 메커니즘으로 락을 걸은 스레드만이 임계 영역을 나갈 때 락을 해제할 수 있습니다. 하지만 Semaphore는 Signaling 메커니즘으로 락을 걸지 않은 스레드도 signal을 사용해 락을 해제할 수 있습니다.